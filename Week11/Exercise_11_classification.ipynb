{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set() #sets the matplotlib style to seaborn style\n",
    "\n",
    "from scipy.io import loadmat \n",
    "from scipy.ndimage import convolve1d\n",
    "from scipy.signal import butter\n",
    "from scipy.signal import sosfiltfilt\n",
    "from scipy.signal import welch\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In exercise 10, we learned basic signal processing techniques. We will apply those techniques in today's exercise on classification-based EMG signal to hand movement decoding.\n",
    "\n",
    "The dataset used here is subject1's data in the second database from the Ninapro dataset (https://ninapro.hevs.ch/instructions/DB1.html). \n",
    "\n",
    "This dataset includes detailed information about the hand movements performed. Our objective now is to predict these movements using the EMG data by classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, first check the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(\"S1_A1_E1.mat\")\n",
    "print(\"Dataset variables:\")\n",
    "for key in data.keys():\n",
    "    if not key.startswith(\"__\"):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg = data[\"emg\"]\n",
    "print(\"EMG data dimension: {}\".format(emg.shape))\n",
    "print(\"EMG data type: {}\".format(type(emg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first channel to get a sense of the data\n",
    "plt.close(\"all\")\n",
    "fig, ax = plt.subplots()\n",
    "EMG_channel = 5\n",
    "ax.plot(emg[:, EMG_channel])   \n",
    "ax.set_title(f\"EMG signal channel {EMG_channel}\")\n",
    "ax.set_xlabel(\"Data points\")\n",
    "ax.set_ylabel(\"Amplitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = data['restimulus']\n",
    "repetition = data['rerepetition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as week 10, for each trial (one repetition of one stimulus) we create a nested list of envelopes of the trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stimuli = len(np.unique(stimulus)) - 1 # -1 because 0 is the resting condition\n",
    "n_repetitions = len(np.unique(repetition)) - 1 # -1 because 0 is not a repetition\n",
    "\n",
    "mov_mean_length = 25\n",
    "mov_mean_weights = np.ones(mov_mean_length) / mov_mean_length\n",
    "\n",
    "#initializing the data structure\n",
    "emg_windows = [[None for repetition_idx in range(n_repetitions)] for stimuli_idx in range(n_stimuli)] \n",
    "emg_envelopes = [[None for repetition_idx in range(n_repetitions)] for stimuli_idx in range(n_stimuli)]\n",
    "\n",
    "for stimuli_idx in range(n_stimuli):\n",
    "    for repetition_idx in range(n_repetitions):\n",
    "        idx = np.logical_and(stimulus == stimuli_idx + 1, repetition == repetition_idx + 1).flatten()\n",
    "        emg_windows[stimuli_idx][repetition_idx] = emg[idx, :]\n",
    "        emg_envelopes[stimuli_idx][repetition_idx] = convolve1d(emg_windows[stimuli_idx][repetition_idx], mov_mean_weights, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using the provided code, we extract the features and build the dataset for classification later. In this simple example we will look at some simple features within the full window of each trial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_from_ninapro(emg, stimulus, repetition, features=None):\n",
    "    # Calculate the number of unique stimuli and repetitions, subtracting 1 to exclude the resting condition\n",
    "    n_stimuli = np.unique(stimulus).size - 1\n",
    "    n_repetitions = np.unique(repetition).size - 1\n",
    "    # Total number of samples is the product of stimuli and repetitions\n",
    "    n_samples = n_stimuli * n_repetitions\n",
    "    \n",
    "    # Number of channels in the EMG data\n",
    "    n_channels = emg.shape[1]\n",
    "    # Calculate the total number of features by summing the number of channels for each feature\n",
    "    n_features = sum(n_channels for feature in features)\n",
    "    \n",
    "    # Initialize the dataset and labels arrays with zeros\n",
    "    dataset = np.zeros((n_samples, n_features))\n",
    "    labels = np.zeros(n_samples)\n",
    "    current_sample_index = 0\n",
    "    \n",
    "    # Loop over each stimulus and repetition to extract features\n",
    "    for i in range(n_stimuli):\n",
    "        for j in range(n_repetitions):\n",
    "            # Assign the label for the current sample\n",
    "            labels[current_sample_index] = i + 1\n",
    "            # Calculate the current sample index based on stimulus and repetition\n",
    "            current_sample_index = i * n_repetitions + j\n",
    "            current_feature_index = 0\n",
    "            # Select the time steps corresponding to the current stimulus and repetition\n",
    "            selected_tsteps = np.logical_and(stimulus == i + 1, repetition == j + 1).squeeze()\n",
    "            \n",
    "            # Loop over each feature function provided\n",
    "            for feature in features:\n",
    "                # Determine the indices in the dataset where the current feature will be stored\n",
    "                selected_features = np.arange(current_feature_index, current_feature_index + n_channels)\n",
    "                # Apply the feature function to the selected EMG data and store the result\n",
    "                dataset[current_sample_index, selected_features] = feature(emg[selected_tsteps, :])\n",
    "                # Update the feature index for the next feature\n",
    "                current_feature_index += n_channels\n",
    "\n",
    "            # Move to the next sample\n",
    "            current_sample_index += 1\n",
    "            \n",
    "    # Return the constructed dataset and corresponding labels\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implement the features. For more information, see\n",
    "\n",
    "1. [Real-Time EMG Based Pattern Recognition Control for Hand Prostheses: A Review on Existing Methods, Challenges and Future Implementation](https://doi.org/10.3390/s19204596)\n",
    "2. [Evaluation of the forearm EMG signal features for the control of a prosthetic hand](https://doi.org/10.1088/0967-3334/24/2/307)\n",
    "\n",
    "(You have access to the papers as EPFL student, if it doesn't work on the VM you can try on your local machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features \n",
    "\n",
    "# Mean absolute value (MAV)\n",
    "mav = lambda x: np.mean(np.abs(x), axis=0)\n",
    "# Standard Deviation (STD)\n",
    "std = ??? # Implement this feature\n",
    "'''\n",
    "------------------------------- After implementing the two features above, carry on with the code before implementing the other features -----------------------------------\n",
    "'''\n",
    "# # Maximum absolute Value (MaxAV)\n",
    "# maxav = ??? # Implement this feature\n",
    "# # Root mean square (RMS)\n",
    "# rms = ??? # Implement this feature\n",
    "# # Waveform length (WL)\n",
    "# wl = ??? # Implement this feature\n",
    "# # Slope sign changes (SSC)\n",
    "# ssc = ??? # Implement this feature\n",
    "\n",
    "#Feel free to add more features, e.g. frequency domain features from the two papers \n",
    "\n",
    "\n",
    "dataset, labels = build_dataset_from_ninapro(\n",
    "    emg=emg,\n",
    "    stimulus=stimulus,\n",
    "    repetition=repetition,\n",
    "    features=[mav, std]\n",
    "    # features=[mav, std, maxav, rms, wl, ssc] # Uncomment this line to use all features once implemented\n",
    ")\n",
    "\n",
    "print(f\"dataset dimension: {dataset.shape}\")\n",
    "print(f\"labels dimension: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 12 actions and 10 repeats for each actions, we have a total of 120 training examples. This is a small classification problem.\n",
    "\n",
    "Now, lets try to do some classification.\n",
    "\n",
    "In this exercise, we will perform a basic classification task using a k-Nearest Neighbors classifier. For more information, check scikit-learn's [KNeighborClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n",
    "\n",
    "We will split our dataset into training and testing sets using [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), normalize the data, train the CLF, and evaluate its performance. This process is fundamental in machine learning and helps us understand how well our model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# Here, 30% of the data is reserved for testing, and 70% is used for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=???)\n",
    "\n",
    "# Normalizing the data\n",
    "# StandardScaler is used to scale the features so that they have a mean of 0 and a standard deviation of 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_z = scaler.fit_transform(X_train)  # Fit the scaler on the training data and transform it\n",
    "X_test_z = scaler.transform(X_test)        # Transform the test data using the same scaler\n",
    "\n",
    "# Train a classifier on the normalized data\n",
    "# We are using K-Nearest Neighbors (KNN) from sklearn\n",
    "clf = KNeighborsClassifier()\n",
    "clf.???  # Fit the model on the training data\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "# Predict the labels for the test set\n",
    "y_pred = clf.???\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score: {accuracy}\")\n",
    "\n",
    "# Create a confusion matrix to visualize the performance of the classification\n",
    "# The confusion matrix shows the true vs predicted labels\n",
    "confmat = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(confmat, annot=True, ax=ax)  # Use seaborn to create a heatmap of the confusion matrix\n",
    "ax.set_ylabel(\"True label\")\n",
    "ax.set_xlabel(\"Predicted label\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation for evaluation\n",
    "\n",
    "In the previous example, we used a random method to split the data into training and testing sets. It's important to note that the model's performance can vary significantly depending on this split. \n",
    "\n",
    "Therefore, in our next step, we plan to vary the composition of the training and testing datasets and train multiple models accordingly. This approach is known as cross-validation, and it helps in assessing the model's effectiveness more reliably by using different data subsets for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation in Machine Learning\n",
    "\n",
    "Cross-validation is a key technique in machine learning for estimating model performance on independent datasets. It mitigates the limitations of a single train-test split, which can yield misleading metrics, especially with small or uneven datasets. The process involves dividing the dataset into 'k' folds, training the model on 'k-1' folds, and testing on the remaining fold, repeated 'k' times. Stratified K-Fold ensures each fold maintains the dataset's class distribution, crucial for imbalanced classes.\n",
    "\n",
    "The advantages of cross-validation include providing a robust performance estimate by averaging results across folds, identifying overfitting, and aiding in hyperparameter tuning. Typically, it is implemented using [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) from [sklearn.model_selection](https://scikit-learn.org/1.5/api/sklearn.model_selection.html), automating data splitting, training, and evaluation. This approach ensures reliable and generalizable model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(???, ???, ???, cv=5)\n",
    "print(f\"Accuracy scores of all models: {scores}\")\n",
    "print(f\"Mean accuracy across all models: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, the 5 different models are trained and evaluated. Each model is trained on a different training and testing set. We see that depending on how the data is split, the performance could vary. Hence, we can then use the average performance for our evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "Something that we can do to improve classification is also to optimize the parameters of the models. For instance, in the K nearest neighbour function on sklearn, we have the option to select various values for 'n_neighbors', 'weights'. To effectively test the different combinations of these parameters, we can utilize the [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) function of sklearn, which is designed to methodically identify the optimal combination of these parameters, thereby ensuring the best possible performance and accuracy for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross validation to find the best hyperparameters for SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [1,3,5,7,9],\n",
    "    \"weights\": ['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "grid = ???(KNeighborsClassifier(), param_grid)\n",
    "grid.???\n",
    "\n",
    "print(f\"Best estimator: {grid.best_estimator_}\")\n",
    "print(f\"Best hyperparameters: {grid.best_params_}\")\n",
    "\n",
    "y_pred = ???\n",
    "\n",
    "accuracy = ???\n",
    "print(f\"Accuracy score of best model: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see how the accuracy increased by searching for the best parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance/selection\n",
    "\n",
    "In this example, we are dealing with a relatively small set of features. However, in scenarios where we encounter a larger number of features, it can be important to employ feature selection techniques to improve model performance and efficiency. \n",
    "\n",
    "For this purpose, we propose a method that utilizes functions like [mutual_info_classif](https://scikit-learn.org/1.5/modules/generated/sklearn.feature_selection.mutual_info_classif.html) and [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) from sklearn. \n",
    "\n",
    "Mutual_info_classif evaluates the mutual information between each feature and the target variable, providing an insight into the relevance of each feature. \n",
    "\n",
    "Meanwhile, SelectKBest allows us to select a specified number of features that have the highest scores according to a given scoring function, in this case, the mutual information.  \n",
    "By combining these two functions, we can effectively reduce the feature space to those most relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions for feature selection\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Calculate mutual information between each feature and the target variable.\n",
    "# Mutual information is a measure of the dependency between variables.\n",
    "# A higher value indicates a stronger relationship.\n",
    "mutual_info = mutual_info_classif(X_train_z, y_train)\n",
    "print(f\"Estimated mutual information between each feature and the target:\\n {mutual_info}\\n\")\n",
    "\n",
    "# Select the top 10 features based on mutual information scores.\n",
    "# Note: You can change 'k' to 30 if you are working with more features.\n",
    "k_best = ???(mutual_info_classif, k=10)\n",
    "k_best.fit(X_train_z, y_train)\n",
    "\n",
    "# Transform the training and test datasets to only include the selected features.\n",
    "X_train_best = k_best.transform(X_train_z)\n",
    "X_test_best = k_best.transform(X_test_z)\n",
    "\n",
    "clf = KNeighborsClassifier(**grid.best_params_) # use the best parameters found before, You can also perform another round of grid search with the new features\n",
    "clf.fit(X_train_best, y_train)\n",
    "\n",
    "# Predict the labels for the test set using the trained model.\n",
    "y_pred = clf.predict(X_test_best)\n",
    "\n",
    "# Calculate the accuracy of the model with the selected features.\n",
    "# Accuracy is the ratio of correctly predicted instances to the total instances.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy score of a model with k best features: {accuracy}\")\n",
    "\n",
    "# Create a confusion matrix to visualize the performance of the classification model.\n",
    "# The confusion matrix shows the true vs predicted labels.\n",
    "confmat = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
    "\n",
    "# Plot the confusion matrix using a heatmap for better visualization.\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(confmat, annot=True, ax=ax)\n",
    "ax.set_ylabel(\"True label\")\n",
    "ax.set_xlabel(\"Predicted label\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nssp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
